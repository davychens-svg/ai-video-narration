{
  "permissions": {
    "allow": [
      "Bash(chmod:*)",
      "WebFetch(domain:docs.moondream.ai)",
      "Bash(./run.sh)",
      "Bash(source:*)",
      "Bash(python:*)",
      "Bash(curl:*)",
      "WebFetch(domain:www.figma.com)",
      "Bash(npm install)",
      "Bash(npm run dev:*)",
      "Bash(npm install:*)",
      "Bash(find:*)",
      "WebSearch",
      "Bash(kill:*)",
      "Bash(awk:*)",
      "Bash(xargs kill:*)",
      "Bash(lsof:*)",
      "WebFetch(domain:github.com)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "Bash(pkill:*)",
      "Read(//private/tmp/**)",
      "Bash(tee:*)",
      "Bash(cat:*)",
      "Bash(llama-server:*)",
      "Bash(for i in {1..5})",
      "Bash(do echo \"=== Test $i ===\")",
      "Bash(done)",
      "Read(//Users/chenshi/Desktop/**)",
      "Bash(bash:*)",
      "Bash(git init:*)",
      "Bash(git add:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nInitial commit: AI Video Narration System\n\nFeatures:\n- Real-time video analysis with SmolVLM and Moondream models\n- llama.cpp integration for 98.6% speed improvement (30-36s â†’ 0.3-0.6s)\n- React frontend with WebRTC camera capture\n- FastAPI backend with WebSocket support\n- Configurable prompts and video quality settings\n- Performance monitoring and latency tracking\n- Complete deployment guides for macOS and Cloud (NVIDIA)\n\nTech Stack:\n- Frontend: React + TypeScript + Vite + TailwindCSS\n- Backend: FastAPI + Python 3.11\n- Inference: llama.cpp + GGUF models\n- AI Models: SmolVLM-500M, Moondream\n- Hardware: Apple Silicon (Metal) / NVIDIA GPU (CUDA)\n\nPerformance:\n- macOS M1/M2: 250-600ms per frame\n- NVIDIA T4/V100/A100: 100-400ms per frame\n- Real-time inference: <1s target achieved\n\nðŸš€ Generated with Claude Code\nEOF\n)\")"
    ],
    "deny": [],
    "ask": []
  }
}
